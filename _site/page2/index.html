<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Latest Posts &#8211; The Training Set</title>
<meta name="description" content="Energy and data, coming at you live from the MARC train.">
<meta name="keywords" content="energy, data, analytics, electricity, modeling">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/design/new_york_concrete_textures_by_fudgegraphics/ny_concrete_1.JPG">

<meta name="twitter:title" content="Latest Posts">
<meta name="twitter:description" content="Energy and data, coming at you live from the MARC train.">
<meta name="twitter:creator" content="@jtelszasz">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Latest Posts">
<meta property="og:description" content="Energy and data, coming at you live from the MARC train.">
<meta property="og:url" content="http://localhost:4000/page2/index.html">
<meta property="og:site_name" content="The Training Set">





<link rel="canonical" href="http://localhost:4000/page2/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="The Training Set Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.min.css">
<!-- Webfonts -->
<link href="http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">



</head>

<body id="post-index" class="feature">

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->
<nav id="dl-menu" class="dl-menuwrapper" role="navigation">
	<button class="dl-trigger">Open Menu</button>
	<ul class="dl-menu">
		<li><a href="http://localhost:4000">Home</a></li>
		<li>
			<a href="#">About</a>
			<ul class="dl-submenu">
				<li>
					<img src="http://localhost:4000/images/bio-photo.jpg" alt="Justin Elszasz photo" class="author-photo">
					<h4>Justin Elszasz</h4>
					<p>Engineering background, indeterminate foreground.</p>
				</li>
				<li><a href="http://localhost:4000/about/">Learn More</a></li>
				
				<li>
					<a href="http://twitter.com/jtelszasz"><i class="fa fa-twitter"></i> Twitter</a>
				</li>
				
				
				<li>
					<a href="http://linkedin.com/in/justinelszasz"><i class="fa fa-linkedin"></i> LinkedIn</a>
				</li>
				<li>
					<a href="http://github.com/jtelszasz"><i class="fa fa-github"></i> GitHub</a>
				</li>
				
				
				
				
			</ul><!-- /.dl-submenu -->
		</li>
		<li>
			<a href="#">Posts</a>
			<ul class="dl-submenu">
				<li><a href="http://localhost:4000/posts/">All Posts</a></li>
				<li><a href="http://localhost:4000/tags/">All Tags</a></li>
			</ul>
		</li>
		<li><a href="http://localhost:4000/the-work/">The Work</a></li>
	</ul><!-- /.dl-menu -->
</nav><!-- /.dl-menuwrapper -->


<div class="entry-header">
  <div class="image-credit">Image source: <a href="http://www.fudgegraphics.com/2009/04/new-york-concrete-10-free-hi-res-textures/">fudgegraphics</a></div><!-- /.image-credit -->
  
    <div class="entry-image">
      <img src="http://localhost:4000/images/design/new_york_concrete_textures_by_fudgegraphics/ny_concrete_1.JPG" alt="Latest Posts">
    </div><!-- /.entry-image -->
  
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>The Training Set</h1>
      <h2>Latest Posts</h2>
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->

<div id="main" role="main">
  
<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-07-31T00:00:00-04:00"><a href="http://localhost:4000/articles/Feeding-The-Data-Monster">July 31, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Feeding-The-Data-Monster" rel="bookmark" title="Feeding the Data Monster" itemprop="url">Feeding the Data Monster</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Scouring the interwebz for some data.</p>

<p>There are a few research questions that I’d like to dig into but I haven’t quite found the right data yet for them.  Ideally I would use our apartment data, but I need at least some summer data (early June won’t count) and we actually just moved apartments.  There are some important differences between the previous and current apartment - namely central AC, larger but less leaky windows, a much larger floor plan, a dishwasher, and a dedicated apartment electric water heater.  </p>

<p>I’ve done some digging to come up with some other candidate datasets, though this is by no means comprehensive.  I’m mainly looking for at least a year worth of hourly electricity data (or finer scale that could be resampled) for a household or apartment with moderate or high summer air conditioning loads. A lot of the publicly available electricity usage datasets I’ve found have been geared toward non-invasive appliance load monitoring (NIALM) research - test data for algorithms that can breakout appliance end uses based on the electricity signatures.  Generally these are very high frequency (sub-minute time scales) but cover much shorter spans than needed (really a full year).  Hopefully this compilation is useful for other researchers out there.</p>

<p>I think I might also put some of these in an appropriate Github folder and turn this post into a readme for future use.  There are plenty more out there that are geared towards the NIALM stuff so if I get into that more, I can add it to the list there.</p>

<h3 id="green-button-sample-datasets">Green Button Sample Datasets</h3>

<p>Since BGE has signed on to use the Green Button data standard (like most utilities using smart meters have) I’m hoping to use a sample dataset, since it would easily be replaced by my own data once it’s available.</p>

<p>The National Institute for Standards and Technology has a <a href="https://collaborate.nist.gov/twiki-sggrid/bin/view/SmartGrid/GreenButtonSDK">list of available sample datasets on their website</a> for the software development kit, or SDK.  It isn’t specified what type of building or location the samples are from, but they do provide hourly profiles that add up to a full year’s worth of data.  This may be worth digging into.</p>

<p>The <a href="https://collaborate.nist.gov/twiki-sggrid/bin/view/SmartGrid/GreenButtonSDK">same NIST website</a> links to some data from San Diego Gas and Electric (SDGE).  There are multiple hourly datasets listed, and they specify a region within SDGE’s territory that the data have come from (coastal, inland, desert, etc.)</p>

<p>I also found <a href="http://www.sdge.com/documents/green-button-60-min-meter-interval-sample-data-csv">this</a> sample on SDGE’s own website.  It’s one year worth of hourly interval electrcity usage data for a residence.  At least looking at this one dataset qualitatively, the A/C loads don’t peak nearly as badly as I’d expect in Baltimore during the summer so I probably won’t use this.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-07/SDGE_Data.png"><img src="http://localhost:4000/images/2014-07/SDGE_data.png" /></a>
  <figcaption>Sample SDGE Green Button electricity usage data.</figcaption>
</figure>
</center>

<h3 id="pecan-street-research-institute">Pecan Street Research Institute</h3>

<p>The <a href="http://www.pecanstreet.org">Pecan Street Research Institute</a> curates possibly the largest residential energy and water consumption dataset.  The effort was initiated in 2009 and monitors the electricity, gas, and water use of over 900 homes in Texas at 1-minute resolution.  The electricity monitoring includes both whole house and up to 23 submetered circuits.  Unfortunately you have to be an active academic researcher to even obtain a free sample of the dataset, let alone full access to the whole shebang.</p>

<h3 id="jack-kelly-phd-student-at-imperial-college">Jack Kelly, PhD student at Imperial College</h3>

<p>Jack Kelly at Imperial College has been gracious enough to post his home monitoring datasets on <a href="https://www.github.com/jackkelly">Github</a>.  He’s been monitoring two homes for electricity usage and sub-minute timescales, neither of which include air-conditioning data.  The lack of air conditioning doesn’t really help me.</p>

<h3 id="kaggle-competition-sample-data">Kaggle Competition Sample Data</h3>

<p><a href="http://www.kaggle.com">Kaggle</a> hosts a platform for open competitions that usually ask competitors to devise machine learning or statistical predicitions, the most accurate prediction winning.  Several of the competitions have involved energy - either forecasting demand or disaggregating demand data into end uses (Kaggle’s actual business involves the application of machine learning for the energy industry).  The <a href="http://www.kaggle.com/c/belkin-energy-disaggregation-competition">disaggregation competition, sponsored by Belkin</a>, asked competitors to try and make use of a particular technique in order to tease out how much energy was used for various appliances.  The data used for this is very high frequency resolution for four houses.</p>

<h3 id="uci-center-for-machine-learning-and-intelligent-systems">UCI Center for Machine Learning and Intelligent Systems</h3>

<p>University of California at Irvine has a center in the computer science department that has sourced a <a href="http://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption">dataset from researchers in Clamart, France</a>.  It appears the minute-resolution, sub-metered data (more than 2 million rows) were recorded by Georges Hebrail et al. for a home in France, but I haven’t been able to find traceback information to confirm.  Unfortunately, while one of the three submeters supposedly captures a water heater and an air conditioner, it’s clear that household member behavior - particularly when it comes to air conditioning - is substantially different than ours.  (This is likely the result of higher energy prices driving reduced consumption, something Americans are only familiar with when gasoline prices jump.)  Since I know our electricity consumption will spike significantly higher this summer, I don’t think this will be a useful dataset.</p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-06-18T00:00:00-04:00"><a href="http://localhost:4000/articles/Closer-Look-At-SVM-Model">June 18, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Closer-Look-At-SVM-Model" rel="bookmark" title="Closer Look at the Electricity SVR Forecast" itemprop="url">Closer Look at the Electricity SVR Forecast</a></h1>
    
  </header>
  <div class="entry-content">
    <p>First a disclaimer on cross-validation:</p>

<p>In the <a href="http://localhost:4000/articles/Predicting-Energy-Use-with-Support-Vector-Machines">previous post</a> I trained a support vector machine model using electricity demand data.  I should state that this is not the end of the analysis nor a robust model ready for release into the wild.  The model would need to undergo cross-validation to forge it into something more robust and generalized.</p>

<p>The data I’m using are the hourly electricity consumption in my apartment between January 18 and March 31, 2014, measured by a smart meter and provided by BGE. The following plot is a closer look at the predicted demand and actual demand over two days from the testing period.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-06/SVM_predict_TS_zoom.png"><img src="http://localhost:4000/images/2014-06/SVM_predict_TS_zoom.png" /></a>
  <figcaption>Predicted (SVR, next-hour) and actual hourly electricity usage, March 25 and 26.</figcaption>
</figure>
</center>

<p>It looks like, with some exceptions, the prediction is generally one hour behind what the actual electricity demand is doing, especially looking at most of the peaks.  At first I thought (hoped) that this was an issue with how I was date indexing the predicted values after calculating them (assigning a timestamp one hour behind what it should have been). But after closer inspection and thinking about it, this actually makes sense.  In the post on <a href="http://localhost:4000/articles/Autocorrelation">autocorrelation</a> I showed the following lag plot: </p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-06/Elec_Lag_1hour.png"><img src="http://localhost:4000/images/2014-06/Elec_Lag_1hour.png" /></a>
  <figcaption>Lag plot, 1 hour.</figcaption>
</figure>
</center>

<p>The slope of the linear fit is about 0.97 and the constant (y-intercept) is about 0.04.  In other words, the ratio between any hour’s electricity demand and the hour previous is about one.  So unless the time of day or workday-non-workday indicator is <em>very</em> influential at any hour (like <a href="http://localhost:4000/articles/Guess-What-Time-Justin-Wakes-Up">6am</a>), the model will likely just predict the next hour to be the same as the current hour demand.  This will result in missing peaks by an hour, which if you’re a utility trying to schedule enough generation in the summer to meet the next hour’s air conditioning loads in a city, this is not so bueno.  I think the reason this is a product of the model is that a large fraction of the training samples used to build the model are <em>not</em> peaks, save for the <a href="http://localhost:4000/articles/Guess-What-Time-Justin-Wakes-Up">6am wake-up time</a>. </p>

<p>Below are the same results, just resampled to daily instead of hourly.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-06/SVM_predict_DailyTotal.png"><img src="http://localhost:4000/images/2014-06/SVM_predict_DailyTotal.png" /></a>
  <figcaption>Hourly demand (actual and predicted) resampled to daily totals.</figcaption>
</figure>
</center>

<h3 id="accuracy-measures">Accuracy Measures</h3>

<p>In order to compare the accuracy of any models, the following measures can be used.  The file <a href="http://www.github.com/jtelszasz/my_energy/forecasts/">“errors.py”</a> has all of these functions for future use.</p>

<p>I’ve calculated and reported the values below and while some do have some absolute meaning, we’ll need to test out some more models to see the relative performance of the model.</p>

<h4 id="root-mean-sqaure-error">Root Mean Sqaure Error</h4>

<p>This is effectively the standard error of the model, and is in the same units as those of the predicted variable (or kilowatt-hours here).</p>

<center>
<img src="http://latex.codecogs.com/gif.latex?RMSE=\sqrt{\frac{\sum_{1}^{N}(y-\hat{y})^{2}}{N}}" title="RMSE=\sqrt{\frac{\sum_{1}^{N}(y-\bar{y})^{2}}{N}}" />
</center>

<p>The standard error for the <a href="http://localhost:4000/articles/Predicting-Energy-Use-with-Support-Vector-Machines">initial SVM model</a> is 0.17 kilowatt-hours.</p>

<h4 id="mean-absolute-percent-error">Mean Absolute Percent Error</h4>

<p>With this measure, the absolute percent error between each predicted value and actual value is calculated and the average is taken; the unit of measure is a percentage. If the absolute value wasn’t taken and there was little bias in the model, you’d end up with something close to zero and the measure would be worthless.  (No I couldn’t get the damn absolute value brackets working in the equation editor and I stopped caring.)</p>

<center>
<img src="http://latex.codecogs.com/gif.latex?MAPE=\frac{1}{N}\sum_{1}^{N}\frac{abs(y-\hat{y})}{y}" title="MAPE=\frac{1}{N}\sum_{1}^{N}\frac{abs(y-\hat{y})}{y}" />
</center>

<p>The mean absolute percent error for the SVM model is 19%.</p>

<h4 id="coefficient-of-variation">Coefficient of Variation</h4>

<p>This is similar to the RMSE measure, except it is normalized to the mean.  It indicates how much variation there is with respect to the mean.</p>

<center>
<img src="http://latex.codecogs.com/gif.latex?CV=\sqrt{\frac{\frac{1}{N-1}\sum_{1}^{N}(y-\hat{y})^{2}}{\bar{y}}}" title="CV=\sqrt{\frac{\frac{1}{N-1}\sum_{1}^{N}(y-\hat{y})^{2}}{\bar{y}}}" />
</center>

<p>The coefficient of variation for the SVM model is 0.21.</p>

<h4 id="mean-bias-error">Mean Bias Error</h4>

<p>The mean bias error gives an indication of how the model over- or underestimates.</p>

<center>
<img src="http://latex.codecogs.com/gif.latex?MBE=\frac{\frac{1}{N-1}\sum_{1}^{N}(y-\hat{y})}{\bar{y}}" title="MBE=\frac{\frac{1}{N-1}\sum_{1}^{N}(y-\hat{y})}{\bar{y}}" />
</center>

<p>The mean bias error for the initial SVM model is -0.02, which indicates the model isn’t systematically over- or underestimating the hourly kilowatt-hour consumption.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-05-08T00:00:00-04:00"><a href="http://localhost:4000/articles/Predicting-Energy-Use-with-Support-Vector-Machines">May 08, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Predicting-Energy-Use-with-Support-Vector-Machines" rel="bookmark" title="Forecasting with Machine Learning" itemprop="url">Forecasting with Machine Learning</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Taking a big jump into machine learning now.</p>

<p>As part of my research in grad school I had started getting interested in the use of machine learning tools for predicting energy consumption.  I went so far as to enroll in a machine learning class, but lacking the some of the statistical/mathematical knowledge for what they were teaching I ended up dropping about three-quarters of the way through.  I’ve since gone back on my own time and learned more statisical inference through online coursework, and am taking a stab at some analysis and coding.</p>

<h3 id="i-thought-we-had-a-model">I Thought We Had a Model</h3>

<p>In <a href="http://localhost:4000/articles/Energy-Use-and-Weather/">another post</a> I plotted electricity consumption against outdoor temperature and fit a straight line to the data.  </p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-05/Elec_and_Temp_OLS.png"><img src="http://localhost:4000/images/2014-05/Elec_and_Temp_OLS.png" /></a>
  <figcaption>Linear ordinary least squares regression model for electricity consumption using outdoor temperature.</figcaption>
</figure>
</center>

<p>Let’s be honest: in terms of predictive capacity, this model sucks.  What if I needed to predict what the electricity consumption would be in the next hour?  The prediction would be on the line - I measure what the outdoor temperature is and read off the corresponding consumption from the blue line.  But look at how far the actual usage is scattered.  Unless I got very lucky, I’d be way off.  (In fact, I think using Bayesian regression I could quantify that probability, but that’s for another post.)</p>

<p>Clearly the linear assumption doesn’t tell the whole story.  It doesn’t capture other aspects of the weather (wind and sun) and especially human behavior that all influence the amount of electricity consumed.  </p>

<h3 id="enter-machine-learning">Enter Machine Learning</h3>

<p>Certainly there are other simpler modeling approaches I can take, and I’d like to learn more about those as well.  But because Python and Scikit-learn have made it so easy and intuitive, I jumped straight into the deep end with support vector machines.  Support vector machines find an <em>optimal</em> regression or classification model, minimizing both the error on the training data while minimizing the complexity of the model itself so that it will be generalized for new data (prediction).</p>

<p>Support vector machines can be used for classification or regression.  As with other machine learning algorithms, the model is first “trained” using a (hopefully large) dataset.  The model parameters are optimized until a balance is struck between errors and model simplicity, a balance that is user adjusted.</p>

<p>I should also say very clearly that I’m not breaking any new ground here, in fact <a href="http://web.eecs.utk.edu/~leparker/publications/Energy-Buildings-2012.pdf">this paper</a> compares several algorithms on similar household energy demand data sets to what I’m using (sensor-based time series) and using similar inputs (weather variables, hour of day, workday/holiday indicator).</p>

<h3 id="modeling">Modeling</h3>

<p>Based on some of the <a href="http://localhost:4000/articles/Autocorrelation">previous explorations of the data</a>, it looked like one hour’s electricity usage could be a very good predictor of the next hour’s usage.  In fact, it looked like it was a much better indicator than the <a href="http://localhost:4000/articles/Energy-Use-and-Weather">outdoor temperature</a>.  I wonder how far that alone will get us.</p>

<p>Well, not completely alone.  There are two other easy time-related variables I’d like to include.  One is the hour of the day (1 through 24, though these each need a feature unto themselves to make each hour equal to a categorical 0 or 1) and a field for whether or not the day was a typical work day or not (“not” would include holidays, weekends, and days I worked from home).  I would expect there to be a pattern of electricity usage associated with both of these variables and we can include them at virtually no modeling expense.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-05/SVM_training_set.png"><img src="http://localhost:4000/images/2014-05/SVM_training_set.png" /></a>
  <figcaption>The training set.</figcaption>
</figure>
</center>

<p>As a training set, I’m using the hourly data between January 18 and March 24.  The testing set will consist of March 25 through March 31.</p>

<h3 id="support-vector-regression-with-scikit-learn">Support Vector Regression with Scikit-learn</h3>

<p>The Scikit-learn package for Python makes using machine learning algorithms simple and clean.  There is even a preprocessing module that does the scaling/normalization that should be done before building a model.</p>

<div class="highlight"><pre><code class="python"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span> <span class="k">as</span> <span class="n">pre</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">pre</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div>

<p>Then to actually train the support vector regression model, I simply call the <em>fit</em> function of the SVR class using the training data-target pairs.</p>

<div class="highlight"><pre><code class="python"><span class="n">SVR_model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">&#39;rbf&#39;</span><span class="p">,</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">gamma</span><span class="o">=.</span><span class="mo">001</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

<p>The kernel <em>rbf</em> is a radial basis function.  This kernel transforms the data into a higher dimensional space when performing the regression.  This generally results in more robust modelling of nonlinearities.  The <em>C</em> and <em>gamma</em> parameters are the user-adjustments I alluded to earlier that allow the model to strike a balance between tightly fitting the training data while keeping the simplest model possible.  For this first test case, I just manually adjusted them by order of magnitude until the <img src="http://latex.codecogs.com/png.latex?R^2" alt="R^2" />  I was getting over the test set was as high as possible.  A better approach would be to do a proper cross-validation that finds the best parameters for the these data.</p>

<p>Now to generate the prediction over the test data, I just call the <em>predict</em> function on the <em>SVM_model</em> object that I created (the trained model).</p>

<div class="highlight"><pre><code class="python"><span class="n">predict_y_array</span> <span class="o">=</span> <span class="n">SVR_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">)</span>
</code></pre></div>

<p>Since I know what the actual hourly usage was over the testing period, I can calculate an <img src="http://latex.codecogs.com/png.latex?R^2" alt="R^2" /> for this testing set, which results in 0.732.</p>

<div class="highlight"><pre><code class="python"><span class="n">SVR_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-05/SVM_predict_TS.png"><img src="http://localhost:4000/images/2014-05/SVM_predict_TS.png" /></a>
  <figcaption>Predicted (SVR, next-hour) and actual hourly electricity usage.</figcaption>
</figure>
</center>

<p>It’s important to remember that this entire timespan wasn’t calculated in one go - each hour’s actual usage would have been used to help predict the next hour’s.  We’re always forecasting the next hour consumption in this scenario.</p>

<p>One way to visualize the accuracy of the predictions is to plot them against the actual values.  If the predictions were 100% accurate, all the points would lie on the 45 degree line shown in black.  It’s a good sign that the points are distributed rather evenly above and below the line; it suggests that there is little bias (systematic under- or over-estimating).  In another post I’ll dig in a little more on evaluating the model.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-05/SVM_plot_errors.png"><img src="http://localhost:4000/images/2014-05/SVM_plot_errors.png" /></a>
  <figcaption>Errors.</figcaption>
</figure>
</center>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-05-05T00:00:00-04:00"><a href="http://localhost:4000/articles/Autocorrelation">May 05, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Autocorrelation" rel="bookmark" title="Electricity Usage Autocorrelation" itemprop="url">Electricity Usage Autocorrelation</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Here’s a quick look using historical data to predict the future.</p>

<p>If the goal is to predict the next hour’s electricity consumption, a good predictor might be the consumption of the hour (or several hours) immediately prior.  One way to assess whether or not this is through the autocorrelation given by:</p>

<center>
<img src="http://latex.codecogs.com/png.latex?R_{h}=\frac{c_{h}}{c_{0}}=\frac{\sum_{t=1}^{N-h}(Y_{t}-\bar{Y})(Y_{t+h}-\bar{Y})}{\sum_{t=1}^{N}(Y_{t}-\bar{Y})^2}  " alt="R_{h}=\frac{c_{h}}{c_{0}}=\frac{\sum_{t=1}^{N-h}(Y_{t}-\bar{Y})(Y_{t+h}-\bar{Y})}{\sum_{t=1}^{N}(Y_{t}-\bar{Y})^2}" />
</center>

<p>This measures the covariance between every point and a particular lag (or number of hours before) with respect to the overall variance.  This is calculated for every possible lag (for 1 hour all the way up to the length of the dataset) and plotted.  If the data were completely random, this would be zero at all time lags.  Again, I’m using the BGE smart meter data for my apartment for January 18 through March 31 of 2014.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-05/Elec_Autocorrelation.png"><img src="http://localhost:4000/images/2014-05/Elec_Autocorrelation.png" /></a>
  <figcaption>Electricity consumption autocorrelation.</figcaption>
</figure>
</center>

<p>Confidence intervals of 95% and 99% are also plotted (solid and dashed horizontal lines, respectively) and so points outside these intervals are statistically significant; that is, the null hypothesis that there is no correlation between the data and its a particular lag is rejected.  For the apartment’s electricity data there is statistically significant from 1 hour lag to approximately 500 hours of lag - the previous 20 days of electricity use are correlated with a typical hour’s elecricity use.</p>

<p>There also appears to be a significant inverse relationship with lag times longer than 600 hours (25 days).  My guess is that this is due to the warming weather between February and March.  This relationship indicates that the electricity consumption for a given hour is typically less than in February - something common sense tells us, but this says that relationship is statistically significant.</p>

<p>If we want to use history as a means for predicting the next hour of consumption, including the entire history would become unwieldy.  To train  model we’d be using an N x N array for training where N is the number of hours for which we’ve been recording data.  For predicting the next hour, we would need a 1 X N vector of all of the N previous hours.  Instead, it would be more computationally efficient if we could reduce the training data set to N x A where A is a small number of strongly correlated indicator hours, say the past 6 hours or so.  To get at this, I’ve plotted a few example lags against the hour’s electricity consumption.  There’s nothing to say that these relationships <em>must</em> be linear, but by plotting the scatter plot and checking the R^2 of the linear fit, it’s clear that for the most part the relationship (at least with immediate history) is linear.</p>

<center>
<figure class="half">
  <a href="http://localhost:4000/images/2014-05/Elec_Lag_1hour.png"><img src="http://localhost:4000/images/2014-05/Elec_Lag_1hour.png" /></a>
  <a href="http://localhost:4000/images/2014-05/Elec_Lag_6hour.png"><img src="http://localhost:4000/images/2014-05/Elec_Lag_6hour.png" /></a>
  <figcaption>Lag plot and linear regression, 1 hour and 6 hour lag.</figcaption>
</figure>

<figure class="half">
  <a href="http://localhost:4000/images/2014-05/Elec_Lag_12hour.png"><img src="http://localhost:4000/images/2014-05/Elec_Lag_12hour.png" /></a>
  <a href="http://localhost:4000/images/2014-05/Elec_Lag_24hour.png"><img src="http://localhost:4000/images/2014-05/Elec_Lag_24hour.png" /></a>
  <figcaption>Lag plot and linear regression, 12 hour and 24 hour lag.</figcaption>


As expected, as the size of the lag increases, the R^2 decreases, meaning the consumption 1 hour before is more relevant than the consumption 24 hours (or more) immediately prior.  If we want to build a predictive model, including the 1 hour lag would be wise.







</figure></center>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-04-18T00:00:00-04:00"><a href="http://localhost:4000/articles/Energy-Use-and-Weather">April 18, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Energy-Use-and-Weather" rel="bookmark" title="Energy Use and Weather" itemprop="url">Energy Use and Weather</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Stepping back, let’s take a look at what the actual time series of the smart meter electricity data looks like for my apartment.</p>

<p>I’ll bring in the hourly outdoor temperature as measured at Baltimore-Washington International Airport (less than 10 miles away as the crow flies).  The data are obtained via the API at <a href="http://www.wunderground.com/weather/api">Weather Underground</a>.  Again, you can follow along my line (curve, circle, some other obscure geometry) of thinking by taking a look at the <a href="http://nbviewer.ipython.org/github/jtelszasz/my_energy/blob/master/My_Energy_And_Weather.ipynb?create=1">iPython notebook</a>.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/Elec_and_Temp_TS.png"><img src="http://localhost:4000/images/2014-04/Elec_and_Temp_TS.png" /></a>
  <figcaption>Time series of hourly electricity consumption and outdoor temperature.</figcaption>
</figure>
</center>

<p>It looks as if there’s an inverse relationship between the outdoor temperature and the apartment’s electricity consumption.  We’d expect this even in the winter for our apartment due to our use of electric resistance heating.  (This is a minority case as many buildings, whether commercial, multi-family, or single-family residential, burn fossil fuels directly for providing heat.  As a precursor to a potential future analysis I’d like to work on using these data, there’s often a debate whether the GHG emissions resulting from electric resistance heating are in fact on par or greater with burning natural gas directly in a furnace on site.  This is due to losses in the electric grid - first the combustion and thermal efficiency of the generation plant itself, then the various lossy inverters required for changing voltages and losses in the transmission lines themselves.  While this is an important question to ask, the broader picture and motivation should be the integration of renewables and storage to provide heat cleanly - electric resistance allows for this integration.)</p>

<p>Back to the temperature vs. electricity use question.  To start digging into the relationship a bit, we’ll start with the scatter plot.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/Elec_and_Temp_Scatter.png"><img src="http://localhost:4000/images/2014-04/Elec_and_Temp_Scatter.png" /></a>
  <figcaption>Scatter plot of hourly electricity consumption and outdoor temperature.</figcaption>
</figure>
</center>

<p>As we’d expect, as the outdoor temperature increases, the electricity use generally decreases.  </p>

<h3 id="statistical-model">Statistical Model</h3>

<p>To take a first crack at quantifying the relationship we can use an ordinary least squares regression to try and quantify that relationship.  As is typically the case with Python, someone has already coded the tools necessary so I just have to import the Statsmodels module and use the right tool.</p>

<p>Running the following block of code…</p>

<div class="highlight"><pre><code class="python"><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">elec_and_weather</span><span class="p">[</span><span class="s">&#39;USAGE&#39;</span><span class="p">],</span><span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">elec_and_weather</span><span class="p">[</span><span class="s">&#39;tempF&#39;</span><span class="p">]))</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="k">print</span> <span class="n">res</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div>

<p>…fits the model to our data and spits out the information about the model.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/Elec_and_Temp_OLS_Output.png"><img src="http://localhost:4000/images/2014-04/Elec_and_Temp_OLS_Output.png" /></a>
  <figcaption>Ordinary least squares regression model.</figcaption>
</figure>
</center>

<p>This is what the model actually looks like on top of the data.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/Elec_and_Temp_OLS.png"><img src="http://localhost:4000/images/2014-04/Elec_and_Temp_OLS.png" /></a>
  <figcaption>Linear ordinary least squares regression model for electricity consumption using outdoor temperature.</figcaption>
</figure>
</center>

<p>So our R^2 shows that 48% of the variation in the electricity use can be explained by the outdoor temperature alone.  The remaining 52% would have to be explained by other variables or natural variability.</p>

<h3 id="engineering-model">Engineering Model</h3>

<p>What are we saying by assuming that the model should be linear?  That (all else being equal) for every degree increase in the outdoor temperature, there should be a proportional decrease in the electricity consumption.  There’s a reason this is a valid assumption, again negelecting the otherwise stochastic behavior as a result of weather and occupancy/behavior.  The underlying heat transfer equation is:</p>

<center>
<img src="http://latex.codecogs.com/png.latex?PBP=\frac{Initial%20Investment}{Annual%20Variable%20Cost%20Savings}" alt="PBP=\frac{Initial%20Investment}{Annual%20Variable%20Cost%20Savings}" />
</center>

<ul>
  <li>where <img src="http://latex.codecogs.com/png.latex?\inline Q" alt="Q" /> is a heat flow rate</li>
  <li><img src="http://latex.codecogs.com/png.latex?\inline h" alt="h" /> is a characteristic heat transfer coefficient</li>
  <li><img src="http://latex.codecogs.com/png.latex?\inline A" alt="A" /> is the perpendicular area through which heat is passing</li>
  <li>and <img src="http://latex.codecogs.com/png.latex?\inline \Delta T" alt="\Delta T" /> is the temperature difference across the boundary through which heat is being transmitted, in this case outdoor and indoor temperature</li>
</ul>

<p>If we were to assume that the behavior in the apartment was constant - the same lights were always on, the same devices were always charging, the refrigerator compressor was always running - if we assumed that the thermostat was always set at 70 degrees, and we assumed that the only part of the weather that ever changed was the temperature (humidity and wind were constant) the linear regression model we ran earlier would exactly mirror this equation.  The variation in the electricity consumption would be entirely explained by the change in outdoor temperature, and the slope of the line would be the overall heat transfer coefficient of the apartment (through walls, windows, doors, floors, ceilings, leakage, etc.) multiplied by the square area of the apartment boundary.  By installing higher R-value insulation in the walls or replacing our old drafty windows with triple-glazing, Argon-filled windows, we’d be altering the overall heat transfer coefficient <img src="http://latex.codecogs.com/png.latex?\inline h" alt="h" /> and effectively reducing the slope of the line we fit to the data.  We can also alter the line’s slope by changing the thermostat setting; remember, the temperature difference <img src="http://latex.codecogs.com/png.latex?\inline \Delta T" alt="\Delta T" /> we’re talking about is the difference between the outdoor and indoor temperatures.</p>

<p>As in all things, there is no true black (statistics) and white (engineering) - there are only grays.  In this regard smart meters can  obviously help us learn about buildings in addition to occupancy/behavior.  With clever algorithms (not the simple linear model I’ve used above) we can start to disaggregate energy consumption into its constituent parts - building response to weather and occupancy behavior.  Indeed, we’ve begun to do this.  For example, BGE recommends different energy efficiency actions I can take based on my consumption patterns.  But this is just a first step in how these data can be used, even just at individual residence level.  I’m imagining exploring in future analyses how to use these data to size battery storage and solar photovoltaics.</p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-04-17T00:00:00-04:00"><a href="http://localhost:4000/articles/More-Smart-Meter-Data">April 17, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/More-Smart-Meter-Data" rel="bookmark" title="More Smart Meter Data..." itemprop="url">More Smart Meter Data...</a></h1>
    
  </header>
  <div class="entry-content">
    <p>In an  <a href="http://localhost:4000/articles/My-BGE-Smart-Meter-Data">earlier post</a>, I showed initial descriptive plots for my electricity use.  Now that we have some more data, we can break these up to see differences as the spring season progresses.</p>

<center>
<figure class="half">
  <a href="http://localhost:4000/images/2014-04/ElecHist - Feb2014.png"><img src="http://localhost:4000/images/2014-04/ElecHist - Feb2014.png" /></a>
  <a href="http://localhost:4000/images/2014-04/ElecHist - Mar2014.png"><img src="http://localhost:4000/images/2014-04/ElecHist - Mar2014.png" /></a>
  <figcaption>Histograms for February and March 2014 electricity consumption.</figcaption>
</figure>
</center>

<p>Another way of showing the difference in each month’s energy consumption patterns would be the cumulative distribution.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/ElecCDF - Feb_March2014.png"><img src="http://localhost:4000/images/2014-04/ElecCDF - Feb_March2014.png" /></a>
  <figcaption>Histogram for February 2014 electricity consumption.</figcaption>
</figure>
</center>

<p>The plot above shows that for a given hourly kilowatt-hour amount, the proportion of hours at which the consumption was that amount or less is substantially higher in March than in April; of course, we’d expect that with the warmer weather.  For example, about 18% of the time in February the hourly consumption was 1 kilowatt-hour or less, while in March it was the case about 70% of the time.</p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-04-16T00:00:00-04:00"><a href="http://localhost:4000/articles/Guess-What-Time-Justin-Wakes-Up">April 16, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/Guess-What-Time-Justin-Wakes-Up" rel="bookmark" title="Guess What Time Justin Wakes Up" itemprop="url">Guess What Time Justin Wakes Up</a></h1>
    
  </header>
  <div class="entry-content">
    <p>First, a little bit on my tools.</p>

<p>For analysis tools, I’m mainly using Python (in the form of iPython notebooks) with the <a href="http://pandas.pydata.org/">Pandas</a> module for data analysis (the sklearn module for machine learning later). Suffice it to say it’s rad.  I also use <a href="https://github.com/jtelszasz">Github</a>, both for my analysis and modeling as well as this blog itself (as you can tell from the current web address), so you’re welcome to peruse or use any of my code from there.  I’ll try to keep my iPython notebooks pretty clean and explained well as a supplement to the blog.  You can find the notebook for the analysis below <a href="http://nbviewer.ipython.org/github/jtelszasz/my_energy/blob/master/My_Energy.ipynb?create=1">here</a>.  (Just click the link - you don’t need anything special to be able to view the notebook.)</p>

<p>Pandas has been great for data analysis and makes things intuitive and quick.  As a mechanical engineer, a lot of my previous work was in Matlab.  It of course has its strengths but for data analysis it always took quite a bit of manual data munging, especially when it came to time series. </p>

<p>Anyways, using the Python groupby function I can manipulate the time series of my hourly electricity consumption from my BGE smart data.  The data starts from January 18 and I now have a few full months of data.  Below is a quick code snipet of how I’m using groupby in this case.</p>

<div class="highlight"><pre><code class="python"><span class="c"># elec_and_weather: hourly electricity usage</span>
<span class="n">elec_and_weather</span><span class="o">.</span><span class="n">groupby</span><span class="p">([(</span><span class="n">elec_and_weather</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dayofweek</span><span class="o">==</span><span class="mi">5</span><span class="p">)</span><span class="o">|</span><span class="p">(</span><span class="n">elec_and_weather</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">dayofweek</span><span class="o">==</span><span class="mi">6</span><span class="p">),</span><span class="n">elec_and_weather</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">hour</span><span class="p">])</span>
</code></pre></div>

<h3 id="the-correct-answer-is">The correct answer is…</h3>

<p>To arrive at the plot below, I actually first sliced the data by month and then applied the groupby shown above.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/AvgDays_Elec_Feb_March.png"><img src="http://localhost:4000/images/2014-04/AvgDays_Elec_Feb_March.png" /></a>
  <figcaption>Average weekday and weekend electricity consumption for February and March of 2014.</figcaption>
</figure>
</center>

<p>This is the “guess what time Justin wakes up for work” plot. The coffee pot consumes 900 W, and we typically have it on for about 20 minutes or so, which would amount to a spike of .3 kWh for that hour. The roommate’s hair dryer consumes 1,875 W and she uses it for about 5 minutes (so she claims, I think I want to see data for that), so that would make for about a .15 kWh spike. Of course that’s what I think a typical day looks like. Not every weekday looked like that (if I worked from home, I probably used the french press instead of the coffee maker, and sometimes the roommate showers the night before and so doesn’t blow dry the hair in the morn). Therefore, the 6am peak in the weekday averages is not quite that high. </p>

<p>Since this spike should be strictly due to behavior, we don’t need to look at the difference between February and March.  We can look at the 5am-6am difference over all the weekday samples thusly:</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-04/Wkday_5am6amDiff - Feb_March.png"><img src="http://localhost:4000/images/2014-04/Wkday_5am6amDiff - Feb_March.png" /></a>
  <figcaption>5am to 6am difference across all weekday samples.</figcaption>
</figure>
</center>

<p>The average weekday difference over this time period between 5am and 6am is .253 kWh.  The 20 minute coffee maker run and the 5 minute blow dryer would amount to .45 kWh.  Looks like that was the case at least a couple of times.</p>

<p>This is a good illustration of privacy concerns around ubiquitous data capture.  Measuring energy consumption is a proxy for measuring human behavior, and while I don’t share a lot of the privacy concerns that many out there do, I can understand why this is problematic.  Suffice it to say, I don’t care that a reader of this blog (are there any?) knows when I wake up (among other things).  Moreover, at larger scales than individual households - say at city block levels - these concerns should start to fade away, as aggregated data can effectively anonymize the information.  </p>


  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-03-16T00:00:00-04:00"><a href="http://localhost:4000/articles/My-BGE-Smart-Meter-Data">March 16, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/My-BGE-Smart-Meter-Data" rel="bookmark" title="My Electricity Use" itemprop="url">My Electricity Use</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Previously, I laid out what BGE’s smart meters are doing in Baltimore. Below is a quick snapshot of the downloaded data for my apartment electricity usage.</p>

<h3 id="green-button">Green Button</h3>

<p>Green Button is the standard by which utilities are providing data to their customers. It was prompted in 2011 by the U.S. Chief Technology Officer calling on industry to standardize accessibility and data format for customer smart meter data and parallels the <a href="">Blue Button</a> concept for health data. Customers can download their interval usage data and use as they see fit. A customer could provide the data to a solar panel installer to better inform the design of the installation, or the data could be used to develop apps that show opportunities for efficiency upgrades.</p>

<h3 id="data">Data</h3>

<p>I’ve downloaded my data from the first date available (Janurary 18, 2014) through the end of February 28, 2014. I’m able to access hourly electrical consumption in kilowatt-hours, and the file is a clean csv. Shown below are probability distributions over those 6 weeks or so. We have electric resistance heating (not central gas-fired heating) and so our consumption during the winter is quite high.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/MyEnergy_ElecHist.png"><img src="http://localhost:4000/images/2014-03/MyEnergy_ElecHist.png" /></a>
  <figcaption>Probability distribution for hourly electricity usage. Data collected January 18, 2014, through February 28, 2014.</figcaption>
</figure>
</center>

<p>Below is the cumulative distribution. For a given kilowatt-hour usage on the horizontal axis, the cumulative function gives the probability that an hour’s usage was that quanitity or less.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/MyEnergy_ElecCDF.png"><img src="http://localhost:4000/images/2014-03/MyEnergy_ElecCDF.png" /></a>
  <figcaption>Cumulative distribution for hourly electricity usage. Data collected January 18, 2014, through February 28, 2014.</figcaption>
</figure>
</center>

<p>Both figures show that there is a higher number of hours spent consuming about 0.5 kilowatt-hours. It may take some weather data to tease out what might be going on there, and I plan to look at the influence of weather next.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-03-15T00:00:00-04:00"><a href="http://localhost:4000/articles/BGE-Smart-Meters">March 15, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/BGE-Smart-Meters" rel="bookmark" title="BGE Smart Meters" itemprop="url">BGE Smart Meters</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Citizens of Baltimore and captive customers of Baltimore Gas &amp; Electric! </p>

<p>In the words of Gabriel, I bring you good tidings of great joy and data and stuff. For the last year or so BGE has been rolling out smart meters to their electricity customers. Our neighborhood was <a href="http://www.bge.com/smartenergy/smartgrid/smartmeters/Pages/Installation-Schedule.aspx">slated for the second half of last year</a>, and lo, our data hath appeared unto us.</p>

<p>BGE indicates that the smart meter upgrades have two components - electricity meter replacement (which communicates every 4 hours) and an upgrade to the natural gas meter that also enables communication (though this only happens every 24 hours). Currently, my BGE dashboard is only showing my electricity consumption so most of the discussion below only applies to electricity. I’ve read their website extensively but have found no indication that we’ll also get to see hourly gas consumption. This is unfortunate for single family home owners who burn natural gas on site for space heating, since this is the <a href="http://www.eia.gov/todayinenergy/detail.cfm?id=10271&amp;src=%E2%80%B9%20Consumption%20%20%20%20%20%20Residential%20Energy%20Consumption%20Survey%20(RECS)-b1">largest portion of their annual energy consumption</a></p>

<p>It appears there are two primary functions the smart meters will initially serve: for providing information to their customers and to monitor the grid for outages. (Apparently even just partial implementation proved their case for grid outage notification during <a href="http://www.greentechmedia.com/articles/read/bge-gets-a-taste-of-smart-meter-capabilities-during-sandy">Hurricane Sandy</a>.) These are two pretty straight-forward applications of the data, I’m wondering where BGE (and other utilities) is headed for the next-step analysis (predictive analytics, grid efficiency and repair, optimization, renewables and storage integration, etc.)</p>

<p>One interesting note on the BGE data privacy policy and a bit of wishful thinking: while BGE can’t disclose or sell individual customer interval data, the <a href="http://www.bge.com/smartenergy/smartgrid/Pages/Data-Privacy-Policy.aspx">BGE website</a> states “Smart Meter interval energy use data that is not specific to the customer, such as combined data, is not included within the scope of this policy.” I think BGE could get ahead of the curve by providing block (or similar aggregate) data in the name of transparency and perhaps as a community service. As they indicate, aggregate data is not covered by the data privacy policy; moreover, the City of Baltimore has followed the suit of many other major cities by establishing an <a href="https://data.baltimorecity.gov">open data repository.</a> Perhaps BGE and the city could work together to post aggregated interval data to Open Baltimore.</p>

<h3 id="comparisons-to-neighbors">Comparisons to Neighbors</h3>

<p>The BGE website does slightly more than just show you historical use, with the most prominent feature being the ability to compare your use to a sample of comparable neighbors. There have been many studies regarding energy consumption reductions as a result of real-time monitoring, feedback, and contextual comparisons (see <a href="http://www1.eere.energy.gov/seeaction/pdfs/customerinformation_behavioral_status_summary.pdf ">here</a>). In fact, a couple friends and a former professor did <a href="http://www.sciencedirect.com/science/article/pii/S0378778813003782">some work</a> on the topic.</p>

<p>In keeping with the data policy exclusion for aggregate data, they use an average of a hundred or so customers that share your characteristics, all within a two or three mile radius of your house (ours average 0.4 miles from us). The initial comparison with which I was presented was way off base because our heating comes from electric resistance, but once I answered a few questions on the website about what appliances we have and the like, the comparison made much more sense (I presume we’re being compared against neighbors who all have electric resistance heating).</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/BGE-dashboard-01.png"><img src="http://localhost:4000/images/2014-03/BGE-dashboard-01.png" /></a>
  <figcaption>February comparison of our electricity use to an average of a hundred or so comparable neighbors and the top 20% most efficient. (source: www.bge.com)</figcaption>
</figure>
</center>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/BGE-dashboard-02.png"><img src="http://localhost:4000/images/2014-03/BGE-dashboard-02.png" /></a>
  <figcaption>Monthly comparison of our electricity use to an average of a hundred or so comparable neighbors and the top 20% most efficient (based on billing data, since smart meters weren't widespread for the shown timeframe). (source: www.bge.com)</figcaption>
</figure>
</center>

<p>Of course, the comparisons of your monthly energy use could have been done with the monthly billing they would have anyways, without the use of smart meters. Using the smart meter data, it looks like soon we’ll be able to compare hour-to-hour use (lending what I would presume will be a more real-time competition feel to things) but this isn’t operational yet. They are, however, displaying the hourly data along with the outdoor dry-bulb temperature for reference.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/BGE-dashboard-04.png"><img src="http://localhost:4000/images/2014-03/BGE-dashboard-04.png" /></a>
  <figcaption>Hourly electricity consumption (kilowatt-hours) and outdoor temperature (degrees Fahrenheit) for March 11, 2014. (source: www.bge.com)</figcaption>
</figure>
</center>
<p>My roommate was home this day. The drop in consumption in the afternoon could be from her leaving the house and shutting off lights and her computer, the weather, or both.  Later I’ll be looking into our apartment’s response to the weather so it might become a bit more apparent then.</p>

<h3 id="disaggregation-and-savings-suggestions">Disaggregation and Savings Suggestions</h3>

<p>Another feature they provide is an estimated breakdown of your electricity consumption into categories (heating, lighting, etc.) Currently, these would have to be static estimates based solely on the answers I provided about our appliances and the like. Farther down the road, the hourly data will have a larger role to play here. Electricity consumption (and energy use in general) is largely a function of two things: the weather and human behavior, both of which can change drastically hour to hour. They’ll likely need about a year’s worth of data to be able to tease out the portion of energy use that is your behavior and the portion that is your building’s response to weather. This is because whatever algorithm they are using to disaggregate weather from behavior will need to have seen your electricity consumption during all climates.</p>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/BGE-dashboard-06.png"><img src="http://localhost:4000/images/2014-03/BGE-dashboard-06.png" /></a>
  <figcaption>Estimated breakdown of electricity consumption based on customer and building characteristics. Also shown, suggestions for reducing usage. (source: www.bge.com)</figcaption>
</figure>
</center>

<p>The disaggregation lends itself to targeted recommendations for how to reduce your electricity consumption. An interesting feature they’ve implemented for more social context is a counter of how many customers have indicated that they would try a particular recommendation (eg. “13,859 people will turn off their lights when not needed; 1,654 people will hang dry their laundry,” etc.) In the same way that “like”-ing a post on Facebook along with many others is in some way a validation that one likes the “right” things, I can see this feature serving to validate one’s choices about their energy consumption.</p>

<p>All in all, this is a good thing. Concerns about radio frequency exposure are rather <a href="http://www.epri.com/abstracts/Pages/ProductAbstract.aspx?ProductId=000000000001021829">unfounded</a> especially when we all carry cell phones in our pockets. If you are someone who has concerns about data privacy, nothing I have to say on the topic will likely alleviate your fears (particularly in light of the fact that I’m posting my energy usage data on a blog). In a later post, I’ll show you more about my data (in the hopes that you show me yours).</p>

<p>UPDATE (05-08-2014): I should mention that the data services and analytics that BGE displays are all powered by <a href="http://www.opower.com/">OPower</a>, one of the leading smart meter analytics companies out there.</p>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->

<article class="hentry">
  <header>
    <div class="entry-meta">
      <span class="entry-date date published updated"><time datetime="2014-03-05T00:00:00-05:00"><a href="http://localhost:4000/articles/GK-Performance-Stats">March 05, 2014</a></time></span><span class="author vcard"><span class="fn"><a href="http://localhost:4000/about/" title="About Justin Elszasz">Justin Elszasz</a></span></span>
      
    </div><!-- /.entry-meta -->
    
      <h1 class="entry-title"><a href="http://localhost:4000/articles/GK-Performance-Stats" rel="bookmark" title="Goalkeeper Performance Stats" itemprop="url">Goalkeeper Performance Stats</a></h1>
    
  </header>
  <div class="entry-content">
    <p>Starting off by looking at some footy data.</p>

<p>In 2012, Manchester City FC and <a href="http://www.optasports.com" title="Opta">Opta</a> (a sports analytics company) teamed up to release a season’s worth of granular data for the 2011-2012 season. Two datasets were released - one with 206 fields containing total game events by player, and another that included x-y locations for passes and shots for each player for the Bolton-Manchester City match on August 21, 2011. There are plenty of other blogs that have been doing football analytics and looking at this data, and I’m likely not to break any new ground. I thought it would be a fun dataset to look at.</p>

<p>Since I’m a goalkeeper, I became interested in measuring the performance of goalkeepers. Having surveyed a number of soccer analytics blogs, goalkeeping seems to be a lesser researched topic and is also potentially more difficult to analyze given the smaller number of events or actions a goalkeeper might take over the course of a game compared to field players. I shouldn’t suggest here that I’ll be breaking new ground or providing revolutionary keeper analysis - I’m no statistics whiz - just letting you on to my motivations.</p>

<p>To kick things off (ugh, I can’t possibly get away with that), I’ve provided some quick and hopefully useful stat tables for the overall season numbers for goalkeepers. I’m only looking at goalkeepers who played 1080 minutes or more (12 games) so we have a reasonable sample size for each goalkeeper. I’ll get to some potential visualizations later, but for now these stats are simple enough that ordered lists are a clear enough way to see some performance metrics. I’m actively choosing not to go the bar graph route; I think they’re terrible for three or more variables.</p>

<p>This would also be a good time to mention the “P90” measures. Since not all players have played the same minutes, it makes sense to normalize their actions to their time played.  Instead of per minute (as in saves per minute or distributions per minute) I think it makes sense to do this on a per 90 minute basis.  Ted Knutson (among others) have done this over at <a href="http://www.statsbomb.com" title="Statsbomb">Statsbomb</a> (which, if anything I’m talking about is interesting to you, you <em>have</em> to check out).</p>

<h3 id="saves">Saves</h3>

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/Saves_Table.png"><img src="http://localhost:4000/images/2014-03/Saves_Table.png" /></a>
  <figcaption>Goalkeeper saves tables, 2011-2012 season .</figcaption>
</figure>
<center>

The simplest way of measuring keeper performance is just to rate them on save percentage (number of shots saved out of number of conceded shots on target). The dataset is also kind enough to us in that they provide short range saves/shots conceded and long range saves/shots conceded. This starts to drill down a bit more into the qualities of the goalkeeper. This is especially true of short range.  For long range shots in the Premier League it should take a true screamer to beat a goalkeeper, so these numbers *should* all be at or near 100%, and are likely more reflective of the number of long-range blinders the team conceded than the keeper's performance.

From the looks of it, de Gea is a top shot-stopper. I'll discuss him a bit with regard to crosses as well.

Szczesny was apparently not very good for Arsenal this season. All three save percentages (all, long-range, and short-range) are near bottom. Granted, these numbers don't tell the whole story. Maybe Szczesny was seeing an abnormally high number of quality, well-placed shots at all ranges. A bit of foreshadowing here: we'll need to look at team defensive performance and shots data to get a better feel for this.

You also see the performance of Mignolet and Begovic starting to stand out. Both were with bottom half of the table teams and were likely facing many more decent chances than a Hart or a De Gea. Of course, Mignolet is now Liverpool's starter and Belgium's number two, and Begovic (despite a howler or two and a current injury) is highly touted.

### Distribution

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/Dist_Table.png"><img src="http://localhost:4000/images/2014-03/Dist_Table.png" /></a>
  <figcaption>Goalkeeper distribution tables, 2011-2012 season.</figcaption>
</figure>
</center>

As in all of these top level stats, the distribution numbers are confounded as well. I think team tactics has a pretty big role to play here. For a possession team, a goalkeeper is going to be picking out short balls and throws and trying to keep his numbers up. Other more direct or counter-attacking sides will want a goalkeeper to quickly get long balls down the field or to the flanks, possibly with lesser rates of success.

I definitely want to do some more work on distribution. You won't get through a televised broadcast of a Premier League match without a former (field) player (probably Eric I-Need-Salsa-For-The-Big-Ass-Chip-On-My-God-Damn-Shoulder Wynalda or Robbie Mustoe) decrying the need for the *modern* goalkeeper to be comfortable on the ball - to assist a team in maintaining possession, meaning make simple passes to nearby defenders while under pressure. Besides just these distribution numbers (which are for distibution after a keeper catches), passing numbers should play a heavy role in determining the ability of a goalkeeper.


### Crosses

<center>
<figure>
  <a href="http://localhost:4000/images/2014-03/Cross_Table.png"><img src="http://localhost:4000/images/2014-03/Cross_Table.png" /></a>
  <figcaption>Goalkeeper distribution tables, 2011-2012 season.</figcaption>
</figure>
</center>

De Gea and Reina quite clearly prefer punching or not challenging for the ball at all to catching. De Gea got quite a bit of flack in this, his first season in the Premier League. From a goalkeeper's prospective, I'd be flaky as all get out on crosses if I started in the Premier League at 23 (granted he was a product of the Atletico Madrid youth academy and was first choice for the first team for about a season and a half there). It's much easier to build confidence on shot-stopping (especially when you are as good and as agile as de Gea) but it's hard to duplicate high pressure, game-like cross scenarios in training.

What these numbers don't tell you is whether a punch was successful in clearing the ball out of danger or not. (For that we'd need to dig pretty deeply into X-Y coordinate data from another dataset.) Obviously if a keeper punches but the ball slips out to an opposing player for a shot, the keeper hasn't really effectively dealt with the cross.

All else being equal, I can't imagine Liverpool and Manchester United were allowing any more dangerous crosses into their box than any other team (which might lead to more punches from the keeper), so I think it's generally a bad thing that both of these keepers were preferring to punch so often. Of course it was De Gea's first season at United, and Reina is no longer with Liverpool, so I guess there you have it.

Anyways, hope some of these numbers are fun or useful to you. I'm definitely having fun digging into this dataset. 





</center></center>

  </div><!-- /.entry-content -->
</article><!-- /.hentry -->


<div class="pagination">
  
    
      <a href="http://localhost:4000" class="btn">Previous</a>
    
  
  <ul class="inline-list">
    <li>
      
        <a href="http://localhost:4000">1</a>
      
    </li>
    
      <li>
        
          <span class="current-page">2</span>
        
      </li>
    
  </ul>
  
    Next
  
</div><!-- /.pagination -->
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2014 Justin Elszasz. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/hpstr/">HPSTR Theme</a>.</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

          

</body>
</html>